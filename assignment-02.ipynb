{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 2: Importing & Exploring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll learn to pull data into our Python environment and run some of the first diagnostics we'll need to understand our data.\n",
    "\n",
    "Why don't you kick us off by importing our two most important data analytic tools into our Jupyter notebook: Pandas and Numpy?\n",
    "\n",
    "## Exercise 1\n",
    "Import Pandas and NumPy into your Jupyter Notebook and assign the standard aliases to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Now let's go straight into importing data into our Python environment! Check out DC's Open Data Portal at opendata.dc.gov.\n",
    "\n",
    "From here, we'll import data into our Python environment in two different ways. First, let's try downloading the data from the website and then pulling it into this notebook. \n",
    "\n",
    "Find the City Service Requests for 2016 in DC's Open Data Portal and download the spreadsheet (.csv file) to your computer.\n",
    "\n",
    "This is a data set containing requests for service through DC's 311 system. People can enter these requests by calling 311, texting DC-311 (32-311), using the 311 app, or visiting the city's online 311 portal. \n",
    "\n",
    "Now let's try pulling the data into our Python environment using Pandas. \n",
    "\n",
    "\n",
    "Pull the .csv file into your Python environment using Pandas and assign it to an object called 'df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? You may have received an error like this: \"OSError: File b'City_Service_Requests_in_2016.csv' does not exist\"\n",
    "\n",
    "This means that the .csv file is not in the directory your notebook is calling from (which is, in fact, the directory the notebook is in). To find out which directory your notebook is calling from, import the os package and get the current working directory.\n",
    "\n",
    "## Exercise 3\n",
    "\n",
    "Import the os package and get the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we know what the current working directory is, we must either change the working directory or move the file into the current working directory. I'll let you decide which you want to do, but this is how you change the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\peter.casey\\\\Downloads') \n",
    "## There's this weird thing in Python where you have to use double slashes when specifying working directories.\n",
    "## If you have trouble getting a file from a directory you know it's in, this is a common error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should be able to pull the data into your Jupyter Notebook. Try it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pull the .csv file directly from the Open Data Portal by using the link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I'm commenting this out because it takes a while to pull the data into the environment because it's a large file\n",
    "#df = pd.read_csv('https://opendata.arcgis.com/datasets/0e4b7d3a83b94a178b3d1f015db901ee_7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You have the data! \n",
    "\n",
    "One of the first things we'd like to know when we're dealing with a data set is its shape; that is the number of rows and columns it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has 302,925 rows and 30 columns. Generally speaking, rows are our \"observations\" or \"samples\", while columns are our \"variables\" or \"features\". \n",
    "\n",
    "Now try getting JUST the number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have an item like this with multiple elements, you can often call the elements by their number. In Python, we always start counting elements with the number '0', so that the first element is always element '0'. \n",
    "\n",
    "## Exercise 4\n",
    "Now try getting the number of columns yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we may want to do is actually LOOK at the data. But you probably don't want to print out all 300,000 rows of data in your notebook! (In reality, Pandas won't do that. Instead, it will show you a subset of the rows.)\n",
    "\n",
    "But to have greater control we can use the head command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11\n",
    "\n",
    "The default head command shows us 5 rows. Try increasing the number of rows it shows us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is sort of any annoying way to look at the data, in my opinion. I'm usually interested in looking at the list of columns and the kinds of values they have, so I usually transpose the data when I print it as a head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can get a sense of what your data looks like. What do you think some of these columns mean?\n",
    "\n",
    "## Exercise 12\n",
    "\n",
    "Think about some of the column names and values you have. What do you think these columns are?\n",
    "\n",
    "We probably want even more information about our variables or columns, so let's learn more about them.\n",
    "\n",
    "First, we can get a quick list of column names this way also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns command provides us with a list of column names.\n",
    "\n",
    "We can also use this command to find out how many columns we have by taking its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this returns the same value as df.shape[1].\n",
    "\n",
    "We can also get column data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see three data types here. What does each mean? Why aren't there any \"date\" types?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 13\n",
    "\n",
    "We'd like to know even more about our data.\n",
    "\n",
    "Use the describe function to learn more about your data. I like to transpose this, too. Try transposing it.\n",
    "\n",
    "Do you notice any columns missing from the output? Why do you think they're missing?\n",
    "\n",
    "You may notice some values are 'NaN'. What does that mean? How might we handle these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The describe function provides us a ton of great information about numeric variables, like integers and floats. But categorical variables, called \"object\" variables in Python, do not have means, mins, maxes, or standard deviations. So how might we analyze these?\n",
    "\n",
    "One of the first steps is to take a look at the unique values of these columns. Let's start with the most interesting one: Service Code Description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SERVICECODEDESCRIPTION'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just did two new things right here: we called a column by using its column name, and we called its unique values.\n",
    "\n",
    "There's another way to call columns from a Pandas DataFrame if you're feeling lazy and don't want to mess around with brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SERVICECODEDESCRIPTION.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 14\n",
    "\n",
    "We can figure out how many unique values we have by getting the length of this object. Try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get value counts for each unique value of a categorical variable using value_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SERVICECODEDESCRIPTION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15\n",
    "\n",
    "What's the most common request? What does that request mean? Check out the District's online 311 portal at 311.dc.gov to learn more about the top service request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 16\n",
    "Take a look at the data using some of the techniques including shape, head, and describe.\n",
    "\n",
    "Recall that we saw that date variables are stored as object data types in Pandas Data Frames.\n",
    "However, we CAN turn them in to datetime types using Pandas's nifty datetime commands.\n",
    "Let's begin by converting the service order date into a new datetime column in our DataFrame called \"request_date\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['request_date'] = pd.to_datetime(df['SERVICEORDERDATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With any datetime object, we can use dt to pull the particulare date time that we're interested in.\n",
    "Here we use the value_counts function to look at the data by month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.request_date.dt.month.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that January is the month in which the city received the most service requests. However, the other top months for service requests are all summer months, and our winter months (December, November, February) are those with the least service requests. Does January seem to be an anomaly? Let's look closer.\n",
    "The value_counts function returns to pieces of information: the values, which are the actual counts of rows or observations, and the index, which the values are grouped by. In this case, the index is the set of months and the values are the number of service requests each month. The value_counts function returns an output that is sorted by the values, but we can also sort by the index using the sort_index function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.request_date.dt.month.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be helpful to plot this output to help us visualize the number of service requests made throughout the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "requests_per_month = df.request_date.dt.month.value_counts()\n",
    "requests_per_month.sort_index().plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "We can see that January does, indeed, look anomalous. After spiking in January, service requests are low throughout the winter months, increasing as we move into the warmer months and peaking in August, after which they dip down again as we return to winter.\n",
    "Let's take a look at what's happening in January. We can focus in on January by selecting the subset of our service requests that came in January.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jan_requests = df[df.request_date.dt.month==1]\n",
    "print(jan_requests.request_date.min())\n",
    "print(jan_requests.request_date.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Here, we've fed Python a logical statement telling it to return values from df where the date-part month in the column 'request_date' is equal to 1 (or January).\n",
    "# Exercise 4\n",
    "To better understand how this works, try taking the command out of the square brackets and running it. What does it return?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns a string of True and False statements. The 'True' values are the ones the DataFrame keeps, and the 'False' ones, it discards.\n",
    "Now that we have the January data, let's look at what kinds of requests were being made in January.\n",
    "\n",
    "## Exercise 17\n",
    "\n",
    "Get value counts for the service code description from the subsample of January service requests. What where the most common requests?\n",
    "\n",
    "The city received a TON of snow removal requests in January 2016, but received very few other requests. It seems that these requests for snow removal are driving the high number of requests in January.\n",
    "If you were living in the District in January 2016, you'll remember this was the month that Snowzilla hit the city. This was a record-breaking snowstorm that dumped feet of snow on the city from January 22nd to January 23rd.\n",
    "Let's take a look at the top request in January, Snow/Ice Removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 18\n",
    "\n",
    "Get the subsample of service requests for Snow/Ice Removal. Get the number of requests for each day in January 2016, then plot those requests so we can look at them over the course of the month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that almost all of the requests for snow and ice removal came in the days following Snowzilla.\n",
    "Now let's take a look at WHERE those requests were coming from. DC is organized into 8 wards. These wards are the largest political geographies in the District. Each ward has a representative on the District Council who is elected directly by the residents of that ward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 19\n",
    "\n",
    "Get the number of requests for snow and ice removal from each of the wards in January 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By far, the most requests for snow and ice removal came from Ward 7, while the fewest (almost a thousand fewer) came from Ward 2.\n",
    "Now let's take a look at response times. Ward 7 had the most requests, but is that an indication that the city was slower to plot roads in Ward 7 than it was in other wards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 20\n",
    "Create a new date column from the resolution date column in our DataFrame of requests for snow and ice removal in January.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the resolution date comes AFTER the service request, the resolution date will always be 'greater' than the request date. We can get the amount of time took the city to respond to each service request by taking the difference between the resolution date and the request date.\n",
    "\n",
    "## Exercise 21\n",
    "\n",
    "Subtract the request date from the resolution date and assign that to an object called \"time_diff\". Print time_diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's convert time_diff to the number of hours it took to respond using the astype function. This function can be used to change the data type of a column. The timedelta64 function lets us convert to the datetime part we're interested in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_diff.astype('timedelta64[h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 22\n",
    "Create a new column in our DataFrame calls \"response_time\" that is the time difference between resolution date and request date in hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our response times, let's use the groupby function to get the average response time by ward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jan_snow_removal.groupby('WARD').response_time.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot like the output from the value_counts function. In fact, value_counts is a type of groupby function that simply returns counts for each of the unique values in a column.\n",
    "The groupby function allows us to aggregate the data by the unique values of a column (or multiple columns) and return various statistics, including mean, median, minimum (min), maximum (max), counts, etc.\n",
    "Again, we have two parts to the output: the index, in this case the ward, and the values, in this case the average hours it to the city to respond to a request for snow and ice removal. The groupby function returns the values sorted by the index. However, we can sort the values by the value using the sort_values function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23\n",
    "Get the average response times by ward again and sort the values by the average response time in ascending order (from highest to lowest). Which ward had the longest response times? Which had the lowest?\n",
    "\n",
    "Now we know which wards made the mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know which wards made the most requests for snow and ice removal following the historic snowstorm in January 2016. Why do you think some wards received faster service than others? Do you think you could build a model predicting which requests would receive the fastest response?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
